# -*- coding: utf-8 -*-
"""SegmentationModel

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17h94ZuYVIvN-qGnN6ZZ7QZQXQVmWbE_s
"""

from google.colab import drive
from google.colab.patches import cv2_imshow
drive.mount("/content/drive/", force_remount=True)
DATA_LOC = "/content/drive/My Drive/Forgery/Data/IEEETry1/dataset-dist/phase-01/"

import tensorflow as tf
print(tf.config.experimental.list_physical_devices())

import os
TRAINING_FAKE_LOCATION = "/content/drive/My Drive/Forgery/Data/dataset-dist/phase-01/training/fake"
TRAINING_GROUND_TRUTH_LOCATION = "/content/drive/My Drive/Forgery/Data/dataset-dist/phase-01/training/ground_truth"
TRAINING_BIN_GROUND_TRUTH_LOCATION = "/content/drive/My Drive/Forgery/Data/dataset-dist/phase-01/training/bin_ground_truth"
print(len(os.listdir(TRAINING_FAKE_LOCATION)))
print(len(os.listdir(TRAINING_GROUND_TRUTH_LOCATION)))
print(len(os.listdir(TRAINING_BIN_GROUND_TRUTH_LOCATION)))

!mkdir "/content/drive/My Drive/Forgery/Data/dataset-dist/phase-01/training/cov_fake"

import cv2
import numpy as np
import matplotlib.pyplot as plt

TRAINING_COV_FAKE_LOCATION ="/content/drive/My Drive/Forgery/Data/dataset-dist/phase-01/training/cov_fake"
fake_files = os.listdir(TRAINING_FAKE_LOCATION)
print(fake_files[3])
for imgnm in fake_files:
  orig = cv2.imread(os.path.join(TRAINING_FAKE_LOCATION, imgnm))
  orig = cv2.resize(orig,(512,512))
  im = np.copy(orig)
  for i in range(im.shape[0]-3+1):
      for j in range(im.shape[1]-3+1):
          kernel = orig[i:i+3,j:j+3]
          mean = np.mean(kernel,axis=(0,1))
          std = np.std(kernel,axis=(0,1))
          im[i+1,j+1] = np.clip((std/mean),0,1)
  im = orig+(2*im)
  im = im.astype('uint8')
  print(".", end="")
  cv2.imwrite(os.path.join(TRAINING_COV_FAKE_LOCATION, imgnm), im*255)

im = orig+(2*im)
im = im.astype('uint8')
# plt.show()
cv2.imwrite(os.path.join(TRAINING_COV_FAKE_LOCATION, fake_files[8]), im*255)
img = cv2.imread(os.path.join(TRAINING_COV_FAKE_LOCATION, fake_files[8]))
plt.imshow(img)
plt.show()

print(len(os.listdir(TRAINING_FAKE_LOCATION)))
print(len(os.listdir(TRAINING_GROUND_TRUTH_LOCATION)))
print(len(os.listdir(TRAINING_BIN_GROUND_TRUTH_LOCATION)))

!pip install keras==2.3.1
!pip install segmentation-models
!pip install keras_applications==1.0.8
!pip install image-classifiers==1.0.0
!pip install efficientnet==1.0.0
!pip install tensorflow==2.0.0
!pip install tensorboard==2.0.0
!pip install tensorflow-estimator==2.0.0

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
import cv2
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from tensorflow.keras.utils import to_categorical ,Sequence
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Conv2DTranspose, BatchNormalization, Activation, Dropout
from tensorflow.keras.optimizers import Adadelta, Nadam ,Adam
from tensorflow.keras.models import Model, load_model
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, TensorBoard
import segmentation_models as sm
from segmentation_models import Unet
import os
from glob import glob
from pathlib import Path
import shutil
from tqdm import tqdm_notebook
from random import sample, choice

import pickle
import os
def storepickle(pickle_files, location, obj):
      print("Storing in pickle file", location,end=" :: ")
      with open(os.path.join(pickle_files, location), 'wb') as f:
          pickle.dump(obj, f)
          if os.path.isfile(os.path.join(pickle_files, location)):
              print("*"*10, "Pickle file Stored", "*"*10)

def loadpickle(pickle_files, location):
    print("Loading from pickle file", location, end=" :: ")
    if os.path.isfile(os.path.join(pickle_files, location)):
        with open(os.path.join(pickle_files, location), 'rb') as f:
            obj = pickle.load(f)
            print("*"*10, "Pickle file Loaded!", "*"*10)
            return obj
    else:
        print("#"*5, "PICKLE FILE CORRUPTED!!!" ,"#"*5)

def mypickle(pickle_files, location, obj = None):
    if obj == None:
        return loadpickle(os.path.join(pickle_files, location))
    else:
        storepickle(os.path.join(pickle_files, location), obj)

import os
PICKLES =  "/content/drive/My Drive/Forgery/pickles_p2"
TRAINING_FAKE_LOCATION = "/content/drive/My Drive/Forgery/Data/dataset-dist/phase-01/training/fake"
TRAINING_GROUND_TRUTH_LOCATION = "/content/drive/My Drive/Forgery/Data/dataset-dist/phase-01/training/ground_truth"
TRAINING_BIN_GROUND_TRUTH_LOCATION = "/content/drive/My Drive/Forgery/Data/dataset-dist/phase-01/training/bin_ground_truth"
print(len(os.listdir(TRAINING_FAKE_LOCATION)))
print(len(os.listdir(TRAINING_GROUND_TRUTH_LOCATION)))
print(len(os.listdir(TRAINING_BIN_GROUND_TRUTH_LOCATION)))

'''Function to fetch Mask Name'''
def getMaskName(img_nm):
  if "_rgb." in img_nm:
    return img_nm.split("_rgb")[0]+"_mask.png"
  if ".png" in img_nm:
    return img_nm.split(".png")[0]+".mask.png"

N = 350
TRAIN_IMAGE_NAMES = os.listdir(TRAINING_FAKE_LOCATION)
TRAIN_MASK_NAMES = [os.path.join(TRAINING_BIN_GROUND_TRUTH_LOCATION, getMaskName(img) ) for img in TRAIN_IMAGE_NAMES]
TRAIN_IMAGE_NAMES = [os.path.join(TRAINING_FAKE_LOCATION, img) for img in TRAIN_IMAGE_NAMES]

TEST_IMAGE_NAMES = TRAIN_IMAGE_NAMES[N:]
TEST_MASK_NAMES = TRAIN_MASK_NAMES[N:]
TRAIN_IMAGE_NAMES =  TRAIN_IMAGE_NAMES[:N]
TRAIN_MASK_NAMES = TRAIN_MASK_NAMES[:N]

print(len(TRAIN_IMAGE_NAMES), len(TRAIN_MASK_NAMES))
print(len(TEST_IMAGE_NAMES), len(TEST_MASK_NAMES))

import imgaug.augmenters as ia
aug2 = ia.Fliplr(1)
aug3 = ia.Flipud(1)
aug4 = ia.Emboss(alpha=(1), strength=1)
aug5 = ia.DirectedEdgeDetect(alpha=(0.8), direction=(1.0))
aug6 = ia.Sharpen(alpha=(1.0), lightness=(1.5))

def normalize_image(mask):
    mask = np.clip(mask/255.0,0,1)
    return mask

class Dataset:
    CLASSES = ['non-edited','edited']

    def __init__(
            self,
            input_paths,
            output_paths,
            classes=None,
            augmentation=None,
            preprocessing=None,):



        self.images_fps = input_paths
        self.masks_fps = output_paths

        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]

        self.augmentation = augmentation
        self.preprocessing = preprocessing

    def __getitem__(self, i):

        image =cv2.imread(self.images_fps[i], cv2.IMREAD_UNCHANGED)
        mas = cv2.imread(self.masks_fps[i], cv2.IMREAD_UNCHANGED)
        image = cv2.resize(image,(512,512))[:,:,(2,1,0)]
        mas = cv2.resize(mas,(512,512))
        image_mask = normalize_image(mas)
        image = normalize_image(image)

        image_masks = [(image_mask == v) for v in self.class_values]
        image_mask = np.stack(image_masks, axis=-1).astype('float')

        a = np.random.uniform()
        if a<0.2:
            image = aug2.augment_image(image)
            image_mask = aug2.augment_image(image_mask)
        elif a<0.4:
            image = aug3.augment_image(image)
            image_mask = aug3.augment_image(image_mask)
        elif a<0.6:
            image = aug4.augment_image(image)
            image_mask = aug4.augment_image(image_mask)
        elif a<0.8:
            image = aug5.augment_image(image)
            image_mask = image_mask
        else:
            image = aug6.augment_image(image)
            image_mask = aug6.augment_image(image_mask)


        return image, image_mask

    def __len__(self):
        return len(self.images_fps)


class Dataloder(tf.keras.utils.Sequence):
    def __init__(self, dataset, batch_size=1, shuffle=False):
        self.dataset = dataset
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indexes = np.arange(len(dataset))

        self.on_epoch_end()

    def __getitem__(self, i):

        # collect batch data
        start = i * self.batch_size
        stop = (i + 1) * self.batch_size
        data = []
        for j in range(start, stop):
            data.append(self.dataset[j])

        batch = [np.stack(samples, axis=0) for samples in zip(*data)]

        return tuple(batch)

    def __len__(self):
        return len(self.indexes) // self.batch_size

    def on_epoch_end(self):
        if self.shuffle:
            self.indexes = np.random.permutation(self.indexes)

from tensorflow.python.framework import tensor_util
def is_tensor(x):
    return tensor_util.is_tensor(x)

"""# Unet"""

# define optomizer
optim = tf.keras.optimizers.Adam(0.0001)

dice_loss = sm.losses.DiceLoss()
focal_loss = sm.losses.BinaryFocalLoss()
total_loss = dice_loss + (1 * focal_loss)

metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]
model = Unet('resnet34', encoder_weights='imagenet', classes=1, activation='sigmoid', input_shape=(512,512,3))
# compile keras model with defined optimozer, loss and metrics
model.compile(optim, total_loss, metrics)
MODEL_FILE = os.path.join(PICKLES, "UNET_i.h5")
print(MODEL_FILE)

BACKBONE = 'efficientnetb3'
BATCH_SIZE = 8
preprocess_input = sm.get_preprocessing(BACKBONE)

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(TRAIN_IMAGE_NAMES, TRAIN_MASK_NAMES, test_size=0.20)
print(len(X_train),len(X_val),len(y_train),len(y_val))

# Dataset for train images
CLASSES = ['edited']
dir_path = ""
train_dataset = Dataset(X_train,y_train, classes=CLASSES)
val_dataset  = Dataset(X_val,y_val, classes=CLASSES)
test_dataset  = Dataset(TEST_IMAGE_NAMES,TEST_MASK_NAMES, classes=CLASSES)


train_dataloader = Dataloder(train_dataset, batch_size=8, shuffle=True)
val_dataloader = Dataloder(val_dataset, batch_size=8, shuffle=True)
test_dataloader = Dataloder(test_dataset, batch_size=8, shuffle=True)

print(train_dataloader[0][0].shape,train_dataloader[0][1].shape)
assert train_dataloader[0][0].shape == (BATCH_SIZE, 512, 512, 3)
assert train_dataloader[0][1].shape == (BATCH_SIZE, 512, 512, 1)

print(MODEL_FILE)
if os.path.exists(MODEL_FILE):
    print("SEGMENT MODEL LOCATION FOUND IN: ", MODEL_FILE)
    model.load_weights(MODEL_FILE)

if os.path.exists(MODEL_FILE):
    print("CHUNK MODEL LOCATION FOUND IN: ", MODEL_FILE)
    model.load_weights(MODEL_FILE)
else:
    print("CHUNK MODEL NOT FOUND", MODEL_FILE)
print("***** Model weight loaded *****")
checkpoint = ModelCheckpoint(MODEL_FILE, monitor='val_iou_score', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]

history = model.fit_generator(train_dataloader, steps_per_epoch=len(val_dataloader), epochs=15,
                              validation_data=val_dataloader,validation_steps=len(val_dataloader),callbacks=callbacks_list)

if os.path.exists(MODEL_FILE):
    print("CHUNK MODEL LOCATION FOUND IN: ", MODEL_FILE)
    model.load_weights(MODEL_FILE)
else:
    print("CHUNK MODEL NOT FOUND", MODEL_FILE)
print("***** Model weight loaded *****")

for each in zip(TRAIN_IMAGE_NAMES[:4],TRAIN_MASK_NAMES[:4]):
    image_mask=cv2.imread(each[1], cv2.IMREAD_UNCHANGED)
    image_mask = cv2.resize(image_mask, (512,512))
    plt.figure(figsize=(15,6))

    plt.subplot(141)
    image=cv2.imread(each[0], cv2.IMREAD_UNCHANGED)
    image = cv2.resize(image, (512,512))
    plt.imshow(image)
    plt.title('original-image')

    plt.subplot(142)
    plt.imshow(image_mask, cmap='gray', vmax=1, vmin=0)
    plt.title('mask')

    # plt.subplot(143)
    # plt.imshow(image)
    # plt.title('pre-processed-image')
    image = tf.cast(image, tf.float32)
    predicted = model.predict(np.asarray([image[:,:, :3]]))
    plt.subplot(143)
    plt.imshow(predicted[0,:,:,0], cmap='gray', vmax=1, vmin=0)
    plt.title('predicted-mask')
    plt.show()

import tensorflow
physical_devices = tensorflow.config.experimental.list_physical_devices('GPU')
try:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)
except:
    pass

checkpoint = ModelCheckpoint(MODEL_FILE, monitor='val_iou_score', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
model.load_weights(MODEL_FILE)
history = model.fit_generator(train_dataloader, steps_per_epoch=len(train_dataloader), epochs=5,
                              validation_data=test_dataloader,validation_steps=len(test_dataloader),callbacks=callbacks_list)

import tensorflow as tf
print(tf.config.experimental.list_physical_devices())

model.load_weights(MODEL_FILE)
for each in zip(TEST_IMAGE_NAMES[:4],TEST_MASK_NAMES[:4]):
    image=cv2.imread(each[0], cv2.IMREAD_UNCHANGED)[:,:,(2,1,0)]/255.0
    image = cv2.resize(image, (512,512))
    orig = cv2.imread(each[0])
    orig = cv2.resize(orig,(512,512))
    predicted = model.predict(image[np.newaxis,:,:,:])
    image_mask=cv2.imread(each[1], cv2.IMREAD_UNCHANGED)
    image_mask = cv2.resize(image_mask, (512,512))
    plt.figure(figsize=(15,6))
    plt.subplot(141)
    plt.imshow(orig)
    plt.title('original-image')
    plt.subplot(142)
    plt.imshow(image_mask, cmap='gray', vmax=1, vmin=0)
    plt.title('mask')
    plt.subplot(143)
    plt.imshow(image)
    plt.title('pre-processed-image')
    plt.subplot(144)
    plt.imshow(predicted[0,:,:,0], cmap='gray', vmax=1, vmin=0)
    plt.title('predicted-mask')
    plt.show()

model.load_weights(MODEL_FILE)
print("Evaluate on Train data")
results = model.evaluate_generator(train_dataloader)
print("Train loss, Train F1 Score, Train IOU Score ", results)
print("*"*10)

print("Evaluate on Validation data")
results = model.evaluate_generator(val_dataloader)
print("Train loss, Train F1 Score, Train IOU Score ", results)
print("*"*10)

print("Evaluate on test data")
results = model.evaluate_generator(test_dataloader)
print("Train loss, Train F1 Score, Train IOU Score ", results)
print("*"*10)

"""# FPN"""

from segmentation_models import FPN
model = FPN('resnet34', encoder_weights='imagenet', classes=1, activation='sigmoid', input_shape=(512,512,3))
# compile keras model with defined optimozer, loss and metrics
model.compile(optim, total_loss, metrics)

MODEL_FILE = os.path.join(PICKLES, "FPN.h5")

checkpoint = ModelCheckpoint(MODEL_FILE, monitor='val_iou_score', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
history = model.fit_generator(train_dataloader, steps_per_epoch=len(val_dataloader), epochs=15,
                              validation_data=val_dataloader,validation_steps=len(val_dataloader),callbacks=callbacks_list)

def plot_history(history, title="Segmentation Model"):

  fig, axs = plt.subplots(1, 3, figsize=(30, 10))

  # Plot history: Focal Dice Loss

  axs[0].plot(history.history['loss'], label='Focal Dice Loss (training data)')
  axs[ 0].plot(history.history['val_loss'], label='Focal Dice Loss (validation data)')
  axs[0].set_title('Focal Dice Loss '+title)
  axs[ 0].set_ylabel('Focal Dice Loss value')
  axs[ 0].set_xlabel('No. epoch')
  axs[ 0].legend(loc="upper left")
  # plt.show()

  # Plot history: F1-Score
  axs[ 1].plot(history.history['f1-score'], label='F1-Score (training data)')
  axs[ 1].plot(history.history['val_f1-score'], label='F1-Score (validation data)')
  axs[ 1].set_title('F1-Score for '+ title)
  axs[ 1].set_ylabel('F1-Score value')
  axs[ 1].set_xlabel('No. epoch')
  axs[ 1].legend(loc="upper left")
  # plt.show()

  # Plot history: IOU Score
  axs[ 2].plot(history.history['iou_score'], label='IOU Score (training data)')
  axs[ 2].plot(history.history['val_iou_score'], label='IOU Score (validation data)')
  axs[ 2].set_title('IOU Score for'+ title)
  axs[2].set_ylabel('IOU Score value')
  axs[ 2].set_xlabel('No. epoch')
  axs[ 2].legend(loc="upper left")
  plt.show()

plot_history(history)

print("Results for FPN:")
model.load_weights(MODEL_FILE)
results = []
print("Evaluate on Train data")
results.append( model.evaluate_generator(train_dataloader))
print("Train loss, Train F1 Score, Train IOU Score ", results[-1])
print("*"*10)

print("Evaluate on Validation data")
results.append(model.evaluate_generator(val_dataloader))
print("Train loss, Valid F1 Score, Valid IOU Score ", results[-1])
print("*"*10)

print("Evaluate on Test data")
results.append(model.evaluate_generator(test_dataloader))
print("Train loss, Test F1 Score, Test IOU Score ", results[-1])
print("*"*10)

if os.path.exists(MODEL_FILE):
    print("CHUNK MODEL LOCATION FOUND IN: ", MODEL_FILE)
    model.load_weights(MODEL_FILE)
else:
    print("CHUNK MODEL NOT FOUND", MODEL_FILE)
print("***** Model weight loaded *****")

for each in zip(TRAIN_IMAGE_NAMES[:4],TRAIN_MASK_NAMES[:4]):
    image_mask=cv2.imread(each[1], cv2.IMREAD_UNCHANGED)
    image_mask = cv2.resize(image_mask, (512,512))
    plt.figure(figsize=(15,6))

    plt.subplot(141)
    image=cv2.imread(each[0], cv2.IMREAD_UNCHANGED)
    image = cv2.resize(image, (512,512))
    plt.imshow(image)
    plt.title('original-image')

    plt.subplot(142)
    plt.imshow(image_mask, cmap='gray', vmax=1, vmin=0)
    plt.title('mask')

    # plt.subplot(143)
    # plt.imshow(image)
    # plt.title('pre-processed-image')
    image = tf.cast(image, tf.float32)
    predicted = model.predict(np.asarray([image[:,:, :3]]))
    plt.subplot(143)
    plt.imshow(predicted[0,:,:,0], cmap='gray', vmax=1, vmin=0)
    plt.title('predicted-mask')
    plt.show()

"""#Linknet"""

from segmentation_models import Linknet
model = Linknet('resnet34', encoder_weights='imagenet', classes=1, activation='sigmoid', input_shape=(512,512,3))
# compile keras model with defined optimozer, loss and metrics
model.compile(optim, total_loss, metrics)

MODEL_FILE = os.path.join(PICKLES, "Linknet.h5")

checkpoint = ModelCheckpoint(MODEL_FILE, monitor='val_iou_score', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
history = model.fit_generator(train_dataloader, steps_per_epoch=len(val_dataloader), epochs=15,
                              validation_data=val_dataloader,validation_steps=len(val_dataloader),callbacks=callbacks_list)

plot_history(history)

print("Results for LinkNet:")
model.load_weights(MODEL_FILE)
results_linknet = []
print("Evaluate on Train data")
results_linknet.append( model.evaluate_generator(train_dataloader))
print("Train loss, Train F1 Score, Train IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Validation data")
results_linknet.append(model.evaluate_generator(val_dataloader))
print("Train loss, Valid F1 Score, Valid IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Test data")
results_linknet.append(model.evaluate_generator(test_dataloader))
print("Train loss, Test F1 Score, Test IOU Score ", results_linknet[-1])
print("*"*10)

for each in zip(TEST_IMAGE_NAMES[:4],TEST_MASK_NAMES[:4]):
    image_mask=cv2.imread(each[1], cv2.IMREAD_UNCHANGED)
    image_mask = cv2.resize(image_mask, (512,512))
    plt.figure(figsize=(15,6))

    plt.subplot(141)
    image=cv2.imread(each[0], cv2.IMREAD_UNCHANGED)
    image = cv2.resize(image, (512,512))
    plt.imshow(image)
    plt.title('original-image')

    plt.subplot(142)
    plt.imshow(image_mask, cmap='gray', vmax=1, vmin=0)
    plt.title('mask')

    # plt.subplot(143)
    # plt.imshow(image)
    # plt.title('pre-processed-image')
    image = tf.cast(image, tf.float32)
    predicted = model.predict(np.asarray([image]))
    plt.subplot(143)
    plt.imshow(predicted[0,:,:,0], cmap='gray', vmax=1, vmin=0)
    plt.title('predicted-mask')
    plt.show()

"""#PSPNet"""

import tensorflow as tf
class Dataset:
  CLASSES = ["pure", "edited"]
  def __init__(self, input_paths, output_paths, classes=None, augmentation=None, preprocessing=None):
    self.images_filepaths = input_paths
    self.masks_filepaths = output_paths
    self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]
    self.augmentation = augmentation
    self.preprocessing = preprocessing

  def normalize_image(self, mask):
    mask = np.clip(mask/255.0,0,1)
    return mask

  def __getitem__(self, i):
    image = cv2.imread(self.images_filepaths[i], cv2.IMREAD_UNCHANGED)
    mask = cv2.imread(self.masks_filepaths[i], cv2.IMREAD_UNCHANGED)
    image = cv2.resize(image, (528, 528))[:, :, (2,1,0)] # to maintain RGB pattern
    mask = cv2.resize(mask, (528, 528))
    image_mask = self.normalize_image(mask)
    image = self.normalize_image(image)
    image_masks = [(image_mask == v) for v in self.class_values]
    image_mask = np.stack(image_masks, axis=-1).astype('float')

    a = np.random.uniform()
    if a<0.2:
        image = aug2.augment_image(image)
        image_mask = aug2.augment_image(image_mask)
    elif a<0.4:
        image = aug3.augment_image(image)
        image_mask = aug3.augment_image(image_mask)
    elif a<0.6:
        image = aug4.augment_image(image)
        image_mask = aug4.augment_image(image_mask)
    elif a<0.8:
        image = aug5.augment_image(image)
        image_mask = image_mask
    else:
        image = aug6.augment_image(image)
        image_mask = aug6.augment_image(image_mask)

    return image, image_mask

  def __len__(self):
    return len(self.images_filepaths)


class Dataloder(tf.keras.utils.Sequence):
    def __init__(self, dataset, batch_size=1, shuffle=False):
      self.dataset = dataset
      self.batch_size = batch_size
      self.shuffle = shuffle
      self.indexes = np.arange(len(dataset))
      self.on_epoch_end()

    def __getitem__(self, i):

      # collect batch data
      start = i * self.batch_size
      stop = (i + 1) * self.batch_size
      data = []
      for j in range(start, stop):
          data.append(self.dataset[j])

      batch = [np.stack(samples, axis=0) for samples in zip(*data)]

      return tuple(batch)

    def __len__(self):
        return len(self.indexes) // self.batch_size

    def on_epoch_end(self):
        if self.shuffle:
            self.indexes = np.random.permutation(self.indexes)

# Dataset for train images
CLASSES = ['edited']
dir_path = ""
train_dataset = Dataset(X_train,y_train, classes=CLASSES)
val_dataset  = Dataset(X_val,y_val, classes=CLASSES)
test_dataset  = Dataset(TEST_IMAGE_NAMES,TEST_MASK_NAMES, classes=CLASSES)


train_dataloader = Dataloder(train_dataset, batch_size=8, shuffle=True)
val_dataloader = Dataloder(val_dataset, batch_size=8, shuffle=True)
test_dataloader = Dataloder(test_dataset, batch_size=8, shuffle=True)

print(train_dataloader[0][0].shape,train_dataloader[0][1].shape)
assert train_dataloader[0][0].shape == (BATCH_SIZE, 528, 528, 3)
assert train_dataloader[0][1].shape == (BATCH_SIZE, 528, 528, 1)

from segmentation_models import PSPNet
model = PSPNet('resnet34', encoder_weights='imagenet', classes=1, activation='sigmoid', input_shape=(528,528,3)) # this model must need size to be divided by 48
# compile keras model with defined optimozer, loss and metrics
model.compile(optim, total_loss, metrics)

MODEL_FILE = os.path.join(PICKLES, "PSPNet.h5")

checkpoint = ModelCheckpoint(MODEL_FILE, monitor='val_iou_score', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
history = model.fit_generator(train_dataloader, steps_per_epoch=len(val_dataloader), epochs=15,
                              validation_data=val_dataloader,validation_steps=len(val_dataloader),callbacks=callbacks_list)

plot_history(history)

print("Results for PSPNet:")
model.load_weights(MODEL_FILE)
results_linknet = []
print("Evaluate on Train data")
results_linknet.append( model.evaluate_generator(train_dataloader))
print("Train loss, Train F1 Score, Train IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Validation data")
results_linknet.append(model.evaluate_generator(val_dataloader))
print("Train loss, Valid F1 Score, Valid IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Test data")
results_linknet.append(model.evaluate_generator(test_dataloader))
print("Train loss, Test F1 Score, Test IOU Score ", results_linknet[-1])
print("*"*10)

image_size = 528
for each in zip(TEST_IMAGE_NAMES[:4],TEST_MASK_NAMES[:4]):
    image_mask=cv2.imread(each[1], cv2.IMREAD_UNCHANGED)
    image_mask = cv2.resize(image_mask, (image_size,image_size))
    plt.figure(figsize=(15,6))

    plt.subplot(141)
    image=cv2.imread(each[0], cv2.IMREAD_UNCHANGED)
    image = cv2.resize(image, (image_size,image_size))
    plt.imshow(image)
    plt.title('original-image')

    plt.subplot(142)
    plt.imshow(image_mask, cmap='gray', vmax=1, vmin=0)
    plt.title('mask')


    image = tf.cast(image, tf.float32)
    predicted = model.predict(np.asarray([image]))
    plt.subplot(143)
    plt.imshow(predicted[0,:,:,0], cmap='gray', vmax=1, vmin=0)
    plt.title('predicted-mask')
    plt.show()

#Unet with vgg16 base

model = Unet('vgg16', encoder_weights='imagenet', classes=1, activation='sigmoid', input_shape=(512,512,3))  # Please go to the upper block and reload the dataset with size 512
# compile keras model with defined optimozer, loss and metrics
model.compile(optim, total_loss, metrics)
MODEL_FILE = os.path.join(PICKLES, "UNETVGG16.h5")

model.load_weights(MODEL_FILE)

checkpoint = ModelCheckpoint(MODEL_FILE, monitor='val_iou_score', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
history = model.fit_generator(train_dataloader, steps_per_epoch=len(val_dataloader), epochs=15,
                              validation_data=val_dataloader,validation_steps=len(val_dataloader),callbacks=callbacks_list)

plot_history(history)

print("Results for Unet with VGG16:")
model.load_weights(MODEL_FILE)
results_linknet = []
print("Evaluate on Train data")
results_linknet.append( model.evaluate_generator(train_dataloader))
print("Train loss, Train F1 Score, Train IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Validation data")
results_linknet.append(model.evaluate_generator(val_dataloader))
print("Train loss, Valid F1 Score, Valid IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Test data")
results_linknet.append(model.evaluate_generator(test_dataloader))
print("Train loss, Test F1 Score, Test IOU Score ", results_linknet[-1])
print("*"*10)

image_size = 512
for each in zip(TEST_IMAGE_NAMES[16:26],TEST_MASK_NAMES[16:26]):
    image_mask=cv2.imread(each[1], cv2.IMREAD_UNCHANGED)
    image_mask = cv2.resize(image_mask, (image_size,image_size))
    plt.figure(figsize=(15,6))

    plt.subplot(141)
    image=cv2.imread(each[0], cv2.IMREAD_UNCHANGED)
    image = cv2.resize(image, (image_size,image_size))
    plt.imshow(image)
    plt.title('original-image')

    plt.subplot(142)
    plt.imshow(image_mask, cmap='gray', vmax=1, vmin=0)
    plt.title('mask')

    # plt.subplot(143)
    # plt.imshow(image)
    # plt.title('pre-processed-image')
    image = tf.cast(image, tf.float32)
    predicted = model.predict(np.asarray([image]))
    plt.subplot(143)
    plt.imshow(predicted[0,:,:,0], cmap='gray', vmax=1, vmin=0)
    plt.title('predicted-mask')
    plt.show()

from segmentation_models import FPN
model = FPN('vgg16', encoder_weights='imagenet', classes=1, activation='sigmoid', input_shape=(512,512,3))
# compile keras model with defined optimozer, loss and metrics
model.compile(optim, total_loss, metrics)

MODEL_FILE = os.path.join(PICKLES, "FPNVGG16.h5")
checkpoint = ModelCheckpoint(MODEL_FILE, monitor='val_iou_score', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
history = model.fit_generator(train_dataloader, steps_per_epoch=len(val_dataloader), epochs=15,
                              validation_data=val_dataloader,validation_steps=len(val_dataloader),callbacks=callbacks_list)

plot_history(history, " FPN with VGG16")

print("Results for FPN with VGG16:")
model.load_weights(MODEL_FILE)
results_linknet = []
print("Evaluate on Train data")
results_linknet.append( model.evaluate_generator(train_dataloader))
print("Train loss, Train F1 Score, Train IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Validation data")
results_linknet.append(model.evaluate_generator(val_dataloader))
print("Train loss, Valid F1 Score, Valid IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Test data")
results_linknet.append(model.evaluate_generator(test_dataloader))
print("Train loss, Test F1 Score, Test IOU Score ", results_linknet[-1])
print("*"*10)

"""#Link Net"""

from segmentation_models import Linknet
model = Linknet('vgg16', encoder_weights='imagenet', classes=1, activation='sigmoid', input_shape=(512,512,3))
# compile keras model with defined optimozer, loss and metrics
model.compile(optim, total_loss, metrics)

MODEL_FILE = os.path.join(PICKLES, "LinknetVGG16.h5")
checkpoint = ModelCheckpoint(MODEL_FILE, monitor='val_iou_score', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
history = model.fit_generator(train_dataloader, steps_per_epoch=len(val_dataloader), epochs=15,
                              validation_data=val_dataloader,validation_steps=len(val_dataloader),callbacks=callbacks_list)

plot_history(history, " LinkNet with VGG16")

print("Results for LinkNet with VGG16:")
model.load_weights(MODEL_FILE)
results_linknet = []
print("Evaluate on Train data")
results_linknet.append( model.evaluate_generator(train_dataloader))
print("Train loss, Train F1 Score, Train IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Validation data")
results_linknet.append(model.evaluate_generator(val_dataloader))
print("Train loss, Valid F1 Score, Valid IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Test data")
results_linknet.append(model.evaluate_generator(test_dataloader))
print("Train loss, Test F1 Score, Test IOU Score ", results_linknet[-1])
print("*"*10)

"""#PSPNet"""

from segmentation_models import PSPNet
model = PSPNet('vgg16', encoder_weights='imagenet', classes=1, activation='sigmoid', input_shape=(528,528,3)) # this model must need size to be divided by 48
# compile keras model with defined optimozer, loss and metrics
model.compile(optim, total_loss, metrics)

MODEL_FILE = os.path.join(PICKLES, "PSPNetVGG16.h5")
checkpoint = ModelCheckpoint(MODEL_FILE, monitor='val_iou_score', verbose=1, save_best_only=True, mode='max')
callbacks_list = [checkpoint]
history = model.fit_generator(train_dataloader, steps_per_epoch=len(val_dataloader), epochs=15,
                              validation_data=val_dataloader,validation_steps=len(val_dataloader),callbacks=callbacks_list)

plot_history(history, " PSPNet with VGG16")

print("Results for PSPNet with VGG16:")
model.load_weights(MODEL_FILE)
results_linknet = []
print("Evaluate on Train data")
results_linknet.append( model.evaluate_generator(train_dataloader))
print("Train loss, Train F1 Score, Train IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Validation data")
results_linknet.append(model.evaluate_generator(val_dataloader))
print("Train loss, Valid F1 Score, Valid IOU Score ", results_linknet[-1])
print("*"*10)

print("Evaluate on Test data")
results_linknet.append(model.evaluate_generator(test_dataloader))
print("Train loss, Test F1 Score, Test IOU Score ", results_linknet[-1])
print("*"*10)

from tabulate import tabulate
theader = ["Model", "Train", "Valid", "Test"]
loss_table = [
["Unet with Resnet34",    "-1.457922101020813", "-0.7059831023216248", "0.49028486013412476"],
["FPN with Resnet34",     "-0.23323872685432434", "-0.43272727727890015", "-0.0258583202958107"],
["LinkNet with Resnet34", "-1.261600375175476", "-1.2140624523162842", "-0.34312593936920166"],
["PSPNet with Resnet34",  "-0.4412766098976135", "-1.355460524559021", "-0.5171314477920532"],

["Unet with VGG16",       "-1.4816696643829346", "-1.8741811513900757", "-1.6497390270233154"],
["FPN with VGG16",        "-1.1322294473648071", "-1.3550055027008057", "0.14390508830547333"],
["LinkNet with VGG16",    "-0.7276862263679504", "-0.295401394367218", "-0.08686405420303345"],
["PSPNet with VGG16",     "-0.3571106791496277", "-0.6138779520988464", "0.5148853063583374"]

]
###############################################
f1Score_table = [
["Unet with Resnet34",    "1.0823924541473389", "1.0802851915359497", "0.9778529405593872"],
["FPN with Resnet34",     "1.0556273460388184", "1.0679798126220703", "1.024769902229309"],
["LinkNet with Resnet34", "1.0604467391967773", "1.058915376663208", "0.992835283279419"],
["PSPNet with Resnet34",  "1.050763487815857", "1.0548063516616821", "0.9706951975822449"],

["Unet with VGG16",       "1.0289223194122314", "1.040490984916687", "1.020355463027954"],
["FPN with VGG16",        "1.0310697555541992", "1.0519832372665405", "1.030448079109192"],
["LinkNet with VGG16",    "1.0348609685897827", "1.0488321781158447", "1.0091688632965088"],
["PSPNet with VGG16",     "1.0288506746292114", "1.0267692804336548", "0.9854851365089417"]

]
###############################################
IOU_table = [
["Unet with Resnet34",    "1.0384953022003174", "1.0375601053237915", "0.987838864326477"],
["FPN with Resnet34",     "1.0257713794708252", "1.0314122438430786", "1.0102976560592651"],
["LinkNet with Resnet34", "1.028180480003357", "1.0273021459579468", "0.9955115914344788"],
["PSPNet with Resnet34",  "1.0235207080841064", "1.0254915952682495", "0.9849615693092346"],

["Unet with VGG16",       "1.0133036375045776", "1.018782138824463", "1.009061336517334"],
["FPN with VGG16",        "1.0143519639968872", "1.0240739583969116", "1.0142219066619873"],
["LinkNet with VGG16",    "1.0161049365997314", "1.022517442703247", "1.0030614137649536"],
["PSPNet with VGG16",     "1.0132085084915161", "1.0125398635864258", "0.9909819960594177"]

]
print("Dice Loss: ")
print(tabulate(loss_table, headers=theader))
print("*"*20,"-"*10,"*"*20)
print()
print("F1-Score: ")
print(tabulate(f1Score_table, headers=theader))
print("*"*20,"-"*10,"*"*20)
print()
print("IOU Score: ")
print(tabulate(IOU_table, headers=theader))
print("*"*20,"-"*10,"*"*20)

"""### From the above results we can observe:
- For Loss `Unet with VGG16` performed best on unseen data.
- For F1-Score `FPN with VGG16` performed best on unseen data.
- For IOU-Score `FPN with VGG16` performed best on unseen data


"""